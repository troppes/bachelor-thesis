
\section{Solr}

Der erste Kandidat ist Solr. Der Download gestaltet sich hierbei denkbar einfach mit einem großen Download-Knopf direkt auf der Homepage \cite{TheApacheSoftwareFoundation.2019}. Da Solr komplett Open Source ist, kann sich neben den Binary’s auch der Source-Code heruntergeladen werden. 

\subsection{Installation}

Bevor die Installation starten kann, muss zuerst eine Java Version > 8 installiert werden. Ich habe mir daraufhin für Java 11 entschieden, da eine neuere Version von OpenJDK nicht auf dieser Ubuntu-Version verfügbar ist.

Die Development-Installation ist denkbar einfach. Zuerst wird Solr aus dem Archiv entpackt und dann mit \path{bin/solr start} gestartet. Hierbei wurde ich allerdings direkt von 2 Warnungen begrüßt. 

\begin{lstlisting}[frame=single] 
    *** [WARN] *** Your open file limit is currently 1024.
    It should be set to 65000 to avoid operational disruption.

    *** [WARN] ***  Your Max Processes Limit is currently 63918.
    It should be set to 65000 to avoid operational disruption.
\end{lstlisting}

Dieses Problem ließ sich aber schnell mit einer Anpassung in der \path{/etc/security/limits.conf} \ref{lst:limits} lösen. Danach muss sich nur neu eingeloggt werden und die Warnungen waren verschwunden.

\begin{lstlisting}[frame=single, label={lst:limits}] 

    #<domain>                <type>  <item>   <value>
     reitz                   soft   nofile    65000
     reitz                   hard   nproc     65000
     reitz                   soft   nproc     65000
    
\end{lstlisting}

Nun Startete der Server komplett ohne Warnungen. Nun musste nur noch der Port in der hier sehr restriktiven Firewall freigeben werden, es wird sämtliche ankommende Verbindungen geblockt, und schon lief die Weboberfläche ohne Probleme. Dazu dann mehr in den Oberflächen-Teil.

Nun noch die richtige Installation aus Service. In dem entpackten Solr-Ordner findet man ein Installation-Skript. Diese benötigt das gepackte Solr als Argument. Solar legt sich dabei einen eigenen Nutzer an, also müssen die Limits auch für diesen User wieder geändert werden. Solr selbst startet sich unter dem Nutzer solr, der auch alle Rechte für die Verzeichnisse besitzt. Will man also etwas an den Konfigurationsdateien ändern, muss auf diesen Nutzer geloggt werden.

\subsection{Indexierung}

Um mit der Indexierung starten zu können, muss zuerst in sogenannter „Core“ erstellt werden. Dieser ist ein Index mit dazugehörigen Transaktionslog und Konfigurationsdateien. Nur mit diesen ist es möglich Dateien zu indexieren und auf ihnen zu suchen.
Die Erstellung eines Core’s läuft mit dem Befehl: \path{bin/solr create -c <name>} ab. Dieser erscheint daraufhin auch direkt in der Oberfläche. Nun ist das Solr-System bereit für die Indexierung.

Als ich nun über die Oberfläche, unter den Punkt Dataimport meine Datenbank einlesen wollte, ließ mich Solr wissen, dass die solrconfig.xml noch keinen DataImportHandler besitzt.

Um diesen zu erstellen, muss auf den Server zuerst in das Verzeichnis des Core’s gewechselt werden, dies ist normalerweise unter \path{SOLRORDNER/server/solr/CORENAME} zu finden. In dem Verzeichnis gibt es die solrconfig.xml. In dieser muss jetzt der DataImportHandler angegeben werden. \cite{solrref.2019b}

Dafür habe ich zuerst einen passenden Treiber heruntergeladen und diesen nach \path{SOLRORDNER/contrib/dataimporthandler/lib} entpackt. Als Nächstes muss eine XML-Datei definiert werden, die angibt, welche Spalten und Tabellen indiziert werden sollten. {GRAFIK EINFÜGEN}. Nachdem dies geschehen ist, muss man Solr noch sagen, dass es dieses DataImportHandler auch verwenden soll. Dafür muss ein Eintrag in der solrconfig.xml gemacht werden. Ist dies geschehen, kann nun in der Weboberfläche der Crawler über die Daten gelaufen lassen. \cite{IqubalMustafaKaki.2016}

Als ich den Crawler allerdings startete, meldet mir Solr, das wenige Einträge indexiert wurden. Bei genauerer Betrachtung fand ich heraus, dass nur eine Tabelle von Solr betrachtet wurde. Als ich mir nun die Daten dieser Tabelle herausgegeben habe, bemerkte ich, dass nur das Feld „id“ indexiert wurde. Dies liegt daran, dass nur Felder in den Solr-Index geschrieben werden, die vorher im Schema festgelegt wurden. Dieses Schema kann man entweder über die Weboberfläche oder die API geändert werden kann. Es gibt auch eine Möglichkeit, das Schema direkt zu ändern, allerdings ist diese Methode nicht mehr erwünscht, da die API Fehler erkennt und Einträge so direkt ablehnt.


RUNTIME LOW RAM
Requests: 435,026 4,439/s, Fetched: 490,052 5,001/s, Skipped: 0 , Processed: 138,366 1,412/s


\subsection{Oberfläche}

\subsection{Dokumentation}

\subsection{Absetzen einer Anfrage und Integration in PHP}